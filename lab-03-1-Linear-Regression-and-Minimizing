#cost function in pure Python
import numpy as np #numpy 를 불러와서 np로 지정 
#data
X = np.array([1, 2, 3]) #x의 값 지정
Y = np.array([1, 2, 3]) #y 값 지정 
#x (입력값 ) y (출력값) 이 같음 
#cost function
def cost_func(W, X, Y): #W,X,Y에 대한 w 값이 주어졌을 때 cost값을 구하는 함수 
    c = 0 # c값 초기화
    for i in range(len(X)): # X데이터 개수 만큼 반복
        c += (W * X[i] - Y[i]) ** 2 #cost 값을 c에 누적 덧셈 (W*X[1]=가설값 )
    return c / len(X) # X 데이터의 개수로 편차 제곱을 나눠서 평균을 내줌  
#
for feed_W in np.linspace(-3, 5, num=15):# np의 시작과 끝을 지정.feed_w 값이-3부터 5 사이를 15개의 구간으로 나눠 구간 값을 가짐
    curr_cost = cost_func(feed_W, X, Y)
    print("{:6.3f} | {:10.5f}".format(feed_W, curr_cost))
    
#Tensorflow
import tensorflow as tf #tensorflow를 불러와 tf로 지정
import numpy as np #numpy(다차원 데이터 저장.배열연산)를 불러와np로 지정 
tf.enable_eager_execution() #eager_execution을 활성화하여 즉시 실행   
#data
X = np.array([1, 2, 3]) #x 값 지정
Y = np.array([1, 2, 3]) #y 값 지정
def cost_func(W, X, Y): # W,X,Y에 대한 w 값이 주어졌을 때 cost값을 구하는 함수 
  hypothesis = X * W #가설 값 
  return tf.reduce_mean(tf.square(hypothesis - Y)) #가설 값에서 y를 빼고 제곱해서 평균을 내줌 

W_values = np.linspace(-3, 5, num=15) #np의 시작과 끝을 지정.W_values 값이-3부터 5 사이를 15개의 구간으로 나눠 구간 값을 가짐
cost_values = [] #값을 리스트로 받음 

for feed_W in W_values:# 리스트의 값을 하나하나 뽑아내서 fedd_W값으로 넣어줌
    curr_cost = cost_func(feed_W, X, Y) #feed_W값을 cost function함수에 실행 시킨 값으로 curr_cost로 지정
    cost_values.append(curr_cost) #curr_cost값을 cost_values 리스트에 추가
    print("{:6.3f} | {:10.5f}".format(feed_W, curr_cost)) #출력
 #결과
#feed_w    curr_cost  
-3.000 |   74.66667
-2.429 |   54.85714      # w값이 -3에서 5까지 변함 
-1.857 |   38.09524      cost는 w값에 의해서 변함 w가 1일때 최소가 되는 2차함수가 그려짐  
-1.286 |   24.38095
-0.714 |   13.71429
-0.143 |    6.09524
 0.429 |    1.52381
 1.000 |    0.00000
 1.571 |    1.52381
 2.143 |    6.09524
 2.714 |   13.71429
 3.286 |   24.38095
 3.857 |   38.09524
 4.429 |   54.85714
 5.000 |   74.66667
 
#Gradient descent
tf.set_random_seed(0)  # 랜덤 시드를 특정한 값으로 초기화 (다음에 실행할 때도 동일하게 실행되도록)
x_data = [1., 2., 3., 4.] #x_data 지정
y_data = [1., 3., 5., 7.] #y_data 지정

W = tf.Variable(tf.random_normal([1], -100., 100.)) # 정규 분포를 따르는 랜덤한 수를 1개 짜리의 변수로 W에 지정 

for step in range(300): #300번 반복 실행
    hypothesis = W * X # 가설 정의
    cost = tf.reduce_mean(tf.square(hypothesis - Y)) # cost함수 정의
#Gradient descet 수식을 tf로 옮김
    alpha = 0.01 # 상수 값 alpa로 정의
    gradient = tf.reduce_mean(tf.multiply(tf.multiply(W, X) - Y, X)) #가설값에 x를 곱하고 평균을 냄
    descent = W - tf.multiply(alpha, gradient) # descent= 새로운 w값 gradient를 구해서 alpa값을 곱하고 w에서 빼줌
    W.assign(descent) #새로운 W값을 할당 
    
    if step % 10 == 0: # 수행 중 10번에 1번씩 cost와 w값을 출력
        print('{:5} | {:10.4f} | {:10.6f}'.format(
            step, cost.numpy(), W.numpy()[0]))
#결과 
step      cost            w
    0 | 11716.3086 |  48.767971        
   10 |  4504.9126 |  30.619968           #진행이 되면서 cost값이 큰 값을 가지고 있다가 급속히 줄어들어 0에 수렴
   20 |  1732.1364 |  19.366755                  w가 -100과 100사이의 랜덤한 값에서 특정한 값으로 수렴해 감
   30 |   666.0052 |  12.388859
   40 |   256.0785 |   8.062004
   50 |    98.4620 |   5.379007
   60 |    37.8586 |   3.715335
   70 |    14.5566 |   2.683725
   80 |     5.5970 |   2.044044
   90 |     2.1520 |   1.647391
  100 |     0.8275 |   1.401434
  110 |     0.3182 |   1.248922
  120 |     0.1223 |   1.154351
  130 |     0.0470 |   1.095710
  140 |     0.0181 |   1.059348
  150 |     0.0070 |   1.036801
  160 |     0.0027 |   1.022819
  170 |     0.0010 |   1.014150
  180 |     0.0004 |   1.008774
  190 |     0.0002 |   1.005441
  200 |     0.0001 |   1.003374
  210 |     0.0000 |   1.002092
  220 |     0.0000 |   1.001297
  230 |     0.0000 |   1.000804
  240 |     0.0000 |   1.000499
  250 |     0.0000 |   1.000309
  260 |     0.0000 |   1.000192
  270 |     0.0000 |   1.000119
  280 |     0.0000 |   1.000074
  290 |     0.0000 |   1.000046
  
  # w에 랜덤한 값이 아닌 특정한 값을 주어도 같은 값에 수렴함
